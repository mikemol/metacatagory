4. **Observe:** Run streamlit run dashboard.py to inspect the learned manifold.

### **Project Nedge-Topology: The Unified Manifest (v2.0)**

Here is the updated manifest. This incorporates the **Induction Engine** (Self-Repair), the **Reflexive Trainer** (Hebbian Learning), and the **God-Mode Dashboard** (Observability) into the package structure.

This directory tree represents the fully operational **Semantic Manifold Engine**.

---

### **I. The Complete Directory Structure**

Plaintext

nedge-topology/   â”œâ”€â”€ pyproject.toml           \# Build System   â”œâ”€â”€ requirements.txt         \# Updated Dependencies   â”œâ”€â”€ README.md                \# Documentation   â”œâ”€â”€ dashboard.py             \# \[NEW\] God-Mode Control Plane (Streamlit)   â”œâ”€â”€ proofs/                  \# Agda Formal Verification   â”‚   â”œâ”€â”€ RotationalTransport.agda   â”‚   â”œâ”€â”€ TopologicalGating.agda   â”‚   â””â”€â”€ TopologicalSuperposition.agda   â””â”€â”€ nedge\_topology/          \# The Python Package       â”œâ”€â”€ \_\_init\_\_.py          \# \[UPDATED\] API Exports       â”œâ”€â”€ geometry.py          \# RoPE Group Action logic       â”œâ”€â”€ graph.py             \# SPPFNode & PackedNode       â”œâ”€â”€ parser.py            \# Vectorized Earley with Semantic Gating       â”œâ”€â”€ search.py            \# Semantic Search Functor       â”œâ”€â”€ storage.py           \# HDF5 Persistence       â”œâ”€â”€ visualizer.py        \# Graphviz Exporter       â”œâ”€â”€ induction.py         \# \[NEW\] Grammar Repair / Rule Synthesis       â””â”€â”€ train.py             \# \[NEW\] Reflexive Hebbian Training Loop

---

### **II. Updated Configuration Files**

1\. requirements.txt   Added the dashboard dependencies.

Plaintext

torch\>=2.0.0   numpy   h5py\>=3.0.0   graphviz   streamlit   plotly   pandas   scikit-learn

2\. nedge\_topology/\_\_init\_\_.py   Updated to export the new learning modules.

Python

from .geometry import RotationalGeometry   from .graph import SPPFNode, PackedNode   from .parser import TopologicalParser, GrammarRule   from .visualizer import TopologicalVisualizer   from .search import SemanticSearchFunctor   from .storage import TopologicalStore   from .induction import GrammarInducer   from .train import ReflexiveTrainer

\_\_all\_\_ \= \[       "RotationalGeometry",       "SPPFNode",       "PackedNode",       "TopologicalParser",       "GrammarRule",       "TopologicalVisualizer",       "SemanticSearchFunctor",       "TopologicalStore",       "GrammarInducer",       "ReflexiveTrainer"   \]

---

### **III. The New Modules**

3\. nedge\_topology/induction.py   The Repair Functor: Synthesizes rules from parse failures.

Python

import torch   import torch.nn.functional as F   from typing import List   from .parser import TopologicalParser, GrammarRule

class GrammarInducer:       """       Analyzes parse failures to synthesize new topological bridges (Rules).       """       def \_\_init\_\_(self, parser: TopologicalParser):           self.parser \= parser

    def induce(self, tokens: List\[str\]) \-\> List\[GrammarRule\]:           \# 1\. Cliff Detection           cliff\_index \= 0           for i in range(len(tokens), \-1, \-1):               if len(self.parser.chart\[i\]) \> 0:                   cliff\_index \= i                   break                      stranded\_tokens \= tokens\[cliff\_index:\]           if not stranded\_tokens: return \[\]

        \# 2\. Ghost Identification (Missing Expectations)           expectations \= {}            for item in self.parser.chart\[cliff\_index\]:               if not item.is\_complete():                   next\_sym \= item.next\_symbol()                   if self.parser.is\_non\_terminal(next\_sym):                       if next\_sym not in expectations:                           expectations\[next\_sym\] \= \[\]                       expectations\[next\_sym\].append(item)                      if not expectations: return \[\]

        \# 3\. Rule Synthesis (Auto-Encoding)           new\_rules \= \[\]           for expected\_sym in expectations.keys():               \# Combine vector semantics of stranded tokens               combined\_vec \= torch.zeros(self.parser.dim)               for t\_txt in stranded\_tokens:                   seed \= sum(ord(c) for c in t\_txt)                   torch.manual\_seed(seed)                   combined\_vec \+= F.normalize(torch.randn(self.parser.dim), p=2, dim=0)                              combined\_vec \= F.normalize(combined\_vec, p=2, dim=0)                              \# Create Rule: Expected \-\> Stranded               new\_rule \= GrammarRule(expected\_sym, stranded\_tokens, dim=self.parser.dim)               new\_rule.prototype \= combined\_vec               new\_rules.append(new\_rule)                          return new\_rules

4\. nedge\_topology/train.py   The Reflexive Loop: Hebbian Learning \+ Induction.

Python

import torch   import torch.nn.functional as F   import os   from typing import List   from .parser import TopologicalParser, GrammarRule   from .induction import GrammarInducer   from .storage import TopologicalStore

class ReflexiveTrainer:       def \_\_init\_\_(self, rules: List\[GrammarRule\], storage\_path: str, learning\_rate: float \= 0.05):           self.storage\_path \= storage\_path           self.store \= TopologicalStore(storage\_path)           self.learning\_rate \= learning\_rate                      if os.path.exists(storage\_path):               self.parser \= self.store.load(rules)           else:               self.parser \= TopologicalParser(rules, dim=64)                          self.inducer \= GrammarInducer(self.parser)

    def train\_epoch(self, corpus: List\[str\]):           successes \= 0           inductions \= 0           for sentence\_text in corpus:               tokens \= sentence\_text.lower().split()               results \= self.parser.parse(tokens)                              if len(results) \> 0:                   self.\_reinforce(results\[0\])                   successes \+= 1               else:                   new\_rules \= self.inducer.induce(tokens)                   if new\_rules:                       self.parser.rules.extend(new\_rules)                       inductions \+= len(new\_rules)

        self.store.save(self.parser)           return successes, inductions

    def \_reinforce(self, root\_item):           \# Hebbian Drift: Shift prototype towards successful instance           rule \= root\_item.rule           drift \= F.normalize(root\_item.vector\_acc, p=2, dim=0)           new\_proto \= (1.0 \- self.learning\_rate) \* rule.prototype \+ \\                       (self.learning\_rate \* drift)           rule.prototype \= F.normalize(new\_proto, p=2, dim=0)

5\. dashboard.py (Root Directory)   The God-Mode Control Plane.

Python

import streamlit as st   import numpy as np   import pandas as pd   import plotly.express as px   import os   from sklearn.decomposition import PCA   from nedge\_topology import TopologicalParser, GrammarRule, TopologicalStore, TopologicalVisualizer, PackedNode   from nedge\_topology.induction import GrammarInducer

st.set\_page\_config(page\_title="Nedge God-Mode", layout="wide", page\_icon="ðŸŒ€")   st.title("ðŸŒ€ Nedge-Topology: God-Mode Dashboard")

\# sidebar   model\_path \= st.sidebar.text\_input("HDF5 Path", "bootstrap.h5")   if not os.path.exists(model\_path):       st.error("Model not found.")       st.stop()

\# load   dummy\_rules \= \[GrammarRule('S', \['NP', 'VP'\])\]    store \= TopologicalStore(model\_path)   parser \= store.load(dummy\_rules)

tab1, tab2 \= st.tabs(\["ðŸ§  Manifold", "ðŸ”¬ Forensic Parser"\])

with tab1:       nodes, vectors, labels, types \= \[\], \[\], \[\], \[\]       for key, node in parser.packed\_nodes.items():           nodes.append(node)           vectors.append(node.content.numpy())           labels.append(f"{node.label}")           types.append("Packed" if isinstance(node, PackedNode) else "Term")              if vectors:           pca \= PCA(n\_components=3)           proj \= pca.fit\_transform(np.array(vectors))           df \= pd.DataFrame(proj, columns=\["x", "y", "z"\])           df\["label"\] \= labels           df\["type"\] \= types           fig \= px.scatter\_3d(df, x='x', y='y', z='z', color='type', hover\_data=\['label'\])           st.plotly\_chart(fig, use\_container\_width=True)

with tab2:       sent \= st.text\_input("Input", "time flies")       if st.button("Parse"):           tokens \= sent.lower().split()           results \= parser.parse(tokens)           if results:               st.success(f"Success\! {len(results)} derivations.")               viz \= TopologicalVisualizer(parser)               viz.dot\_lines \= \[\]               viz.\_header()               viz.visualize("temp.dot")               st.graphviz\_chart("\\n".join(viz.dot\_lines))           else:               st.error("Failed. Attempting Induction...")               inducer \= GrammarInducer(parser)               new\_rules \= inducer.induce(tokens)               for r in new\_rules:                   st.info(f"Proposed: {r.lhs} \-\> {r.rhs}")

---

### **IV. Deployment Sequence**

1. **Initialize:** Create the folders and files as shown above.   2. **Install:** pip install \-e .   3. **Bootstrap:** Create a script (or use train\_bootstrap.py) to run ReflexiveTrainer on a small corpus. This generates bootstrap.h5.  
