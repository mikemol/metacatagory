### **Project Nedge-Topology: The Adjoint Manifest (v3.0)**

This manifest solidifies the transition to the **Hybrid Geometric Engine**. It replaces the separate geometry modules with a single **Adjoint Engine** that fuses Discrete Symmetry (SymNum) and Continuous Rotation (RoPE), exposing **Topological Tension** as a first-class signal for the parser and dashboard.

---

### **I. Directory Structure**

Plaintext

nedge-topology/   â”œâ”€â”€ pyproject.toml           \# Build System   â”œâ”€â”€ requirements.txt         \# Dependencies (includes Streamlit/Plotly)   â”œâ”€â”€ README.md                \# Documentation   â”œâ”€â”€ dashboard.py             \# \[UPDATED\] God-Mode with Tension Visualization   â”œâ”€â”€ proofs/                  \# Agda Formal Verification   â”‚   â”œâ”€â”€ RotationalTransport.agda   â”‚   â”œâ”€â”€ TopologicalGating.agda   â”‚   â”œâ”€â”€ TopologicalSuperposition.agda   â”‚   â”œâ”€â”€ StasheffCoherence.agda   â”‚   â”œâ”€â”€ NonAbelianTransport.agda   â”‚   â””â”€â”€ AdjointTransport.agda   â””â”€â”€ nedge\_topology/          \# The Python Package       â”œâ”€â”€ \_\_init\_\_.py          \# API Exports       â”œâ”€â”€ geometry.py          \# \[UPDATED\] The Adjoint Engine (SymNum \+ RoPE)       â”œâ”€â”€ graph.py             \# \[UPDATED\] Nodes with Tension State       â”œâ”€â”€ parser.py            \# \[UPDATED\] Dynamic Gating based on Tension       â”œâ”€â”€ search.py            \# Semantic Search Functor       â”œâ”€â”€ storage.py           \# HDF5 Persistence       â”œâ”€â”€ visualizer.py        \# Graphviz Exporter       â”œâ”€â”€ induction.py         \# Grammar Repair       â””â”€â”€ train.py             \# Reflexive Trainer

---

### **II. Critical Module Updates**

#### **1\. nedge\_topology/geometry.py**

*The Engine Room. Fuses SymNum (Structure) and RoPE (Semantics).*

Python

import torch   import math

class ContinuousGeometry:       """       Standard Rotational Position Embedding (U(1) Abelian Group).       Represents fluid, relative semantic distance.       """       @staticmethod       def get\_freqs(dim: int, theta: float \= 10000.0):           half\_dim \= dim // 2           freqs \= 1.0 / (theta \*\* (torch.arange(0, half\_dim, 2).float() / half\_dim))           return freqs

    @staticmethod       def apply(vector: torch.Tensor, index: int) \-\> torch.Tensor:           dim \= vector.shape\[-1\]           half\_dim \= dim // 2                      \# Split: Apply RoPE only to the first half (Semantic Phase)           v\_half \= vector\[..., :half\_dim\]           freqs \= ContinuousGeometry.get\_freqs(dim)           v\_complex \= torch.view\_as\_complex(v\_half.float().reshape(-1, 2))                      angles \= index \* freqs           rot \= torch.polar(torch.ones\_like(angles), angles)                      v\_rotated \= torch.view\_as\_real(v\_complex \* rot).flatten()           return torch.cat(\[v\_rotated, vector\[..., half\_dim:\]\])

class DiscreteGeometry:       """       Dihedral Group D\_n symmetry (Non-Abelian).       Represents rigid grammatical structure slots (SymNum).       """       def \_\_init\_\_(self, dim: int, order\_n: int \= 12):           self.dim \= dim           self.order\_n \= order\_n           assert dim % 2 \== 0

    def \_get\_rotation\_matrix(self, k: int):           theta \= (2 \* math.pi \* k) / self.order\_n           c \= math.cos(theta)           s \= math.sin(theta)           return torch.tensor(\[\[c, \-s\], \[s, c\]\], dtype=torch.float32)

    def apply(self, vector: torch.Tensor, index: int) \-\> torch.Tensor:           \# Apply D\_n rotation to the structural subspace (first 2 dims)           v\_2d \= vector\[..., :2\].unsqueeze(-1)           M \= self.\_get\_rotation\_matrix(index).to(vector.device)           v\_rotated \= torch.matmul(M, v\_2d).squeeze(-1)           return torch.cat(\[v\_rotated, vector\[..., 2:\]\])

class Geometry:       """       The Adjoint Engine.       Combines Continuous and Discrete geometries and measures Tension.       """       def \_\_init\_\_(self, dim: int):           self.continuous \= ContinuousGeometry()           self.discrete \= DiscreteGeometry(dim)

    def apply(self, vector: torch.Tensor, index: int) \-\> torch.Tensor:           v\_cont \= self.continuous.apply(vector, index)           v\_disc \= self.discrete.apply(vector, index)           \# Superposition of Structure and Semantics           return (v\_cont \+ v\_disc) / math.sqrt(2)

    def measure\_tension(self, vector: torch.Tensor, index: int) \-\> float:           """           Quantifies the 'Homological Defect'.           Tension \= Euclidean distance between Ideal (Discrete) and Actual (Continuous).           """           v\_cont \= self.continuous.apply(vector, index)           v\_disc \= self.discrete.apply(vector, index)           return torch.dist(v\_cont, v\_disc).item()

#### **2\. nedge\_topology/graph.py**

*The Data Structure. Now carries the tension state.*

Python

import torch   import math   import torch.nn.functional as F   from typing import List

class SPPFNode:       def \_\_init\_\_(self, content: torch.Tensor, start: int, end: int, label: str):           self.content \= content           self.start \= start           self.end \= end           self.label \= label           self.dim \= content.shape\[-1\]           self.tension \= 0.0  \# Topological Tension state

    def transported\_vector(self, geometry):           \# Transport relative to the start index           return geometry.apply(self.content, self.start)

    def interaction(self, other, geometry):           if not isinstance(other, SPPFNode): return NotImplemented           q \= self.transported\_vector(geometry)           k \= other.transported\_vector(geometry)           return torch.dot(q, k) / math.sqrt(self.dim)

    def \_\_repr\_\_(self):           return f"Node\<{self.label}\>({self.start}:{self.end}, T={self.tension:.2f})"

class PackedNode(SPPFNode):       def \_\_init\_\_(self, start: int, end: int, label: str, dim: int):           super().\_\_init\_\_(torch.zeros(dim), start, end, label)           self.derivations \= \[\]

    def add\_derivation(self, children: List\[SPPFNode\]):           path\_vector \= torch.zeros\_like(self.content)           avg\_tension \= 0.0                      for child in children:               path\_vector \+= child.content               avg\_tension \+= child.tension                      if children:                avg\_tension /= len(children)                      self.content \+= path\_vector           self.derivations.append(children)                      \# Moving average of tension across derivations           n \= len(self.derivations)           self.tension \= (self.tension \* (n \- 1) \+ avg\_tension) / n

        if self.content.norm() \> 1e-9:               self.content \= F.normalize(self.content, p=2, dim=0)

#### **3\. nedge\_topology/parser.py**

*The Functor. Now uses Tension to dynamically adjust Gating.*

Python

import torch   import torch.nn.functional as F   from typing import List   from .graph import SPPFNode, PackedNode   from .geometry import Geometry

RESONANCE\_THRESHOLD \= 0.15   COHERENCE\_THRESHOLD \= 0.10

class GrammarRule:       def \_\_init\_\_(self, lhs: str, rhs: List\[str\], dim: int \= 64):           self.lhs \= lhs           self.rhs \= rhs           self.prototype \= F.normalize(torch.randn(dim), p=2, dim=0)

class EarleyState:       def \_\_init\_\_(self, rule: GrammarRule, dot: int, start: int, current: int,                     vector\_acc: torch.Tensor, children: List\[SPPFNode\]):           self.rule \= rule           self.dot \= dot           self.start \= start           self.current \= current           self.vector\_acc \= vector\_acc           self.children \= children

    def next\_symbol(self):           if self.dot \< len(self.rule.rhs): return self.rule.rhs\[self.dot\]           return None

    def is\_complete(self):           return self.dot \== len(self.rule.rhs)

    def advance(self, child: SPPFNode):           new\_vec \= self.vector\_acc \+ child.content           return EarleyState(               self.rule, self.dot \+ 1, self.start, child.end,                new\_vec, self.children \+ \[child\]           )       def \_\_eq\_\_(self, other):           return (self.rule \== other.rule and self.dot \== other.dot and                    self.start \== other.start and self.current \== other.current)       def \_\_hash\_\_(self):           return hash((self.rule.lhs, self.dot, self.start, self.current))

class TopologicalParser:       def \_\_init\_\_(self, grammar\_rules: List\[GrammarRule\], dim=64):           self.rules \= grammar\_rules           self.dim \= dim           self.chart \= \[\]            self.packed\_nodes \= {}           self.geometry \= Geometry(dim) \# Adjoint Engine

    def parse(self, tokens: List\[str\]):           n \= len(tokens)           self.chart \= \[set() for \_ in range(n \+ 1)\]           self.packed\_nodes \= {}                      for rule in self.rules:               if rule.lhs \== 'S':                   self.chart\[0\].add(EarleyState(rule, 0, 0, 0, torch.zeros(self.dim), \[\]))                      for i in range(n \+ 1):               while True:                   initial\_len \= len(self.chart\[i\])                   current\_items \= list(self.chart\[i\])                   for item in current\_items:                       if item.is\_complete():                           self.complete(item, i)                       else:                           sym \= item.next\_symbol()                           if self.is\_non\_terminal(sym):                               self.predict(sym, i)                   if len(self.chart\[i\]) \== initial\_len: break               if i \< n: self.scan(i, tokens\[i\])                          return \[item for item in self.chart\[n\] if item.rule.lhs \== 'S' and item.start \== 0 and item.is\_complete()\]

    def is\_non\_terminal(self, sym):           return any(r.lhs \== sym for r in self.rules)

    def predict(self, symbol, index):           for rule in self.rules:               if rule.lhs \== symbol:                   self.chart\[index\].add(EarleyState(rule, 0, index, index, torch.zeros(self.dim), \[\]))

    def scan(self, index, token\_text):           seed \= sum(ord(c) for c in token\_text)           torch.manual\_seed(seed)            lexical\_vec \= F.normalize(torch.randn(self.dim), p=2, dim=0)           node \= SPPFNode(lexical\_vec, index, index \+ 1, token\_text)                      \# Initial Tension Calculation           node.tension \= self.geometry.measure\_tension(node.content, node.start)                      for item in self.chart\[index\]:               if not item.is\_complete() and item.next\_symbol() \== token\_text:                   self.chart\[index \+ 1\].add(item.advance(node))

    def complete(self, item: EarleyState, index):           span\_key \= (item.rule.lhs, item.start, index)           if span\_key not in self.packed\_nodes:               self.packed\_nodes\[span\_key\] \= PackedNode(item.start, index, item.rule.lhs, self.dim)                      final\_node \= self.packed\_nodes\[span\_key\]           final\_node.add\_derivation(item.children)                      \# 1\. Calculate Tension for new constituent           final\_node.tension \= self.geometry.measure\_tension(final\_node.content, final\_node.start)                      \# 2\. Dynamic Gating: Higher Tension \= Stricter Gate           dynamic\_threshold \= RESONANCE\_THRESHOLD \+ (final\_node.tension \* 0.1)                      for parent in self.chart\[item.start\]:               if not parent.is\_complete() and parent.next\_symbol() \== item.rule.lhs:                   parent\_proxy \= SPPFNode(parent.vector\_acc, parent.start, parent.current, "ParentState")                                      \# Adjoint Interaction                   resonance \= parent\_proxy.interaction(final\_node, self.geometry)                                      potential\_vec \= parent.vector\_acc \+ final\_node.content                   coherence \= F.cosine\_similarity(potential\_vec.unsqueeze(0), parent.rule.prototype.unsqueeze(0)).item()                                      if resonance \> dynamic\_threshold and coherence \> COHERENCE\_THRESHOLD:                       self.chart\[index\].add(parent.advance(final\_node))

#### **4\. dashboard.py**

*God-Mode. Now Visualizes Tension.*

Python

import streamlit as st   import numpy as np   import pandas as pd   import plotly.express as px   import os   from sklearn.decomposition import PCA   from nedge\_topology import TopologicalParser, GrammarRule, TopologicalStore, TopologicalVisualizer, PackedNode   from nedge\_topology.induction import GrammarInducer

st.set\_page\_config(page\_title="Nedge God-Mode", layout="wide", page\_icon="ðŸŒ€")   st.title("ðŸŒ€ Nedge-Topology: God-Mode Dashboard")

model\_path \= st.sidebar.text\_input("HDF5 Path", "bootstrap.h5")   if not os.path.exists(model\_path):       st.error(f"Model {model\_path} not found.")       st.stop()

dummy\_rules \= \[GrammarRule('S', \['NP', 'VP'\])\]    store \= TopologicalStore(model\_path)   parser \= store.load(dummy\_rules)

tab1, tab2 \= st.tabs(\["ðŸ§  Adjoint Manifold", "ðŸ”¬ Forensic Parser"\])

with tab1:       st.header("Adjoint Manifold Projection")       st.caption("Color and Size indicate Topological Tension (Deviation from Discrete Structure).")              nodes, vectors, labels, types, tensions \= \[\], \[\], \[\], \[\], \[\]       for key, node in parser.packed\_nodes.items():           nodes.append(node)           vectors.append(node.content.numpy())           labels.append(f"{node.label} \[{node.start}:{node.end}\]")           types.append("Packed" if isinstance(node, PackedNode) else "Term")           tensions.append(node.tension)              if vectors:           pca \= PCA(n\_components=3)           proj \= pca.fit\_transform(np.array(vectors))           df \= pd.DataFrame(proj, columns=\["x", "y", "z"\])           df\["label"\] \= labels           df\["type"\] \= types           df\["tension"\] \= tensions                      fig \= px.scatter\_3d(df, x='x', y='y', z='z',                                color='tension', size='tension', size\_max=20,                               hover\_data=\['label', 'type', 'tension'\],                               color\_continuous\_scale=px.colors.sequential.Viridis\_r)           st.plotly\_chart(fig, use\_container\_width=True)

with tab2:       sent \= st.text\_input("Input", "time flies like an arrow")       if st.button("Parse"):           tokens \= sent.lower().split()           results \= parser.parse(tokens)           if results:               st.success(f"Success\! {len(results)} derivations.")               viz \= TopologicalVisualizer(parser)               viz.dot\_lines \= \[\]               viz.\_header()               viz.visualize("temp.dot")               st.graphviz\_chart("\\n".join(viz.dot\_lines))                              st.subheader("Node Tension Inspector")               for key, node in parser.packed\_nodes.items():                   if len(node.derivations) \> 0:                       st.write(f"\*\*{node.label}\*\* \[{node.start}:{node.end}\] T={node.tension:.4f}")           else:               st.error("Failed. Attempting Induction...")               inducer \= GrammarInducer(parser)               new\_rules \= inducer.induce(tokens)               for r in new\_rules:                   st.info(f"Proposed: {r.lhs} \-\> {r.rhs}")

---

### **III. Supporting Files**

**5\. nedge\_topology/\_\_init\_\_.py**

Python

from .geometry import Geometry   from .graph import SPPFNode, PackedNode   from .parser import TopologicalParser, GrammarRule   from .visualizer import TopologicalVisualizer   from .search import SemanticSearchFunctor   from .storage import TopologicalStore   from .induction import GrammarInducer   from .train import ReflexiveTrainer

\_\_all\_\_ \= \[       "Geometry",       "SPPFNode",       "PackedNode",       "TopologicalParser",       "GrammarRule",       "TopologicalVisualizer",       "SemanticSearchFunctor",       "TopologicalStore",       "GrammarInducer",       "ReflexiveTrainer"   \]

**6\. requirements.txt**

Plaintext

torch\>=2.0.0   numpy   h5py\>=3.0.0   graphviz   streamlit   plotly   pandas   scikit-learn  
