Run the run\_bootstrap() script from the previous turn to generate the bootstrap.h5 file, then launch streamlit run dashboard.py to inspect the brain you just created.

### **I. Formal Correction: The Control Plane**

I formally correct the elision of the **Human-in-the-Loop Observer**.

A complex topological system cannot be debugged solely via logs. It requires a **Control Plane** that renders the high-dimensional manifold into a human-perceptible low-dimensional projection. We will use **Streamlit** for the interface and **Plotly** for interactive vector geometry, treating the "Forensic Trace" as a first-class data object.

***

### **II. The Dashboard Code: dashboard.py**

Create this file in your root nedge-topology/ directory.

Python

import streamlit as st   import torch   import torch.nn.functional as F   import pandas as pd   import numpy as np   import plotly.express as px   import graphviz   from sklearn.decomposition import PCA   from sklearn.manifold import TSNE

\# Import our Nedge Engine   from nedge\_topology import TopologicalParser, GrammarRule, SPPFNode, PackedNode   from nedge\_topology.storage import TopologicalStore   from nedge\_topology.visualizer import TopologicalVisualizer   from nedge\_topology.search import SemanticSearchFunctor

\# --- 1. CONFIGURATION ---   st.set\_page\_config(page\_title="Nedge God-Mode", layout="wide", page\_icon="ðŸŒ€")

st.title("ðŸŒ€ Nedge-Topology: God-Mode Dashboard")   st.markdown("### The Unified Topological Control Plane")

\# --- 2. SIDEBAR: CONTROL ---   st.sidebar.header("1. Neural State")   model\_path = st.sidebar.text\_input("HDF5 Path", "bootstrap.h5")

\# Threshold Controls   st.sidebar.header("2. Hyperparameters")   resonance\_thresh = st.sidebar.slider("Resonance Threshold (RoPE)", 0.0, 1.0, 0.15)   coherence\_thresh = st.sidebar.slider("Coherence Threshold (Proto)", 0.0, 1.0, 0.10)

\# --- 3. STATE LOADING ---   @st.cache\_resource   def load\_parser(path):       if not os.path.exists(path):           return None       # Dummy rules for loading (in real app, these are saved or separate)       rules = \[GrammarRule('S', \['NP', 'VP'])]        store = TopologicalStore(path)       return store.load(rules)

import os   parser = load\_parser(model\_path)

if not parser:       st.warning(f"No brain found at \`{model\_path}\`. Run \`train.py\` first!")       st.stop()

\# Patch thresholds dynamically   # (Assuming we modified parser.py to use instance variables, or we monkeypatch class vars)   # For this demo, we assume the parser code uses global constants or we patch them:   import nedge\_topology.parser   nedge\_topology.parser.RESONANCE\_THRESHOLD = resonance\_thresh   nedge\_topology.parser.COHERENCE\_THRESHOLD = coherence\_thresh

\# --- 4. TABBED INTERFACE ---   tab1, tab2, tab3 = st.tabs(\["ðŸ§  Manifold Explorer", "ðŸ”¬ Forensic Parser", "ðŸ“œ Grammar Logic"])

\# === TAB 1: THE MANIFOLD (Vector Space) ===   with tab1:       st.header("Semantic Vector Space Projection")              # Extract Vectors       # We pull all unique SPPFNodes from the packed\_nodes       nodes = \[]       vectors = \[]       labels = \[]       types = \[]              for key, node in parser.packed\_nodes.items():           nodes.append(node)           vectors.append(node.content.numpy())           labels.append(f"{node.label} \[{node.start}:{node.end}]")           types.append("PackedNode" if isinstance(node, PackedNode) else "Terminal")                  if len(vectors) > 0:           X = np.array(vectors)                      # Dimensionality Reduction           dim\_red\_method = st.radio("Projection Method", \["PCA", "t-SNE"])                      if dim\_red\_method == "PCA":               pca = PCA(n\_components=3)               projections = pca.fit\_transform(X)           else:               tsne = TSNE(n\_components=3, random\_state=42)               projections = tsne.fit\_transform(X)                          # DataFrame for Plotly           df = pd.DataFrame(projections, columns=\["x", "y", "z"])           df\["label"] = labels           df\["type"] = types                      fig = px.scatter\_3d(df, x='x', y='y', z='z', color='type',                                hover\_data=\['label'], symbol='type',                               title="3D Semantic Manifold",                               color\_discrete\_map={"PackedNode": "#00CC96", "Terminal": "#EF553B"})           st.plotly\_chart(fig, use\_container\_width=True)       else:           st.info("Manifold is empty.")

\# === TAB 2: FORENSIC PARSER ===   with tab2:       st.header("Forensic Parse Trace")              col1, col2 = st.columns(\[1, 3])              with col1:           sentence = st.text\_input("Input Sentence", "time flies like an arrow")           run\_btn = st.button("Run Forensic Parse")                  if run\_btn:           tokens = sentence.lower().split()                      # We wrap the parser to capture the trace           # (In a real deployment, the parser would have a 'trace=True' flag)           # For visualization, we just run the standard parse and visualize the result.                      results = parser.parse(tokens)                      with col2:               if results:                   st.success(f"Parse Successful! Found {len(results)} valid derivations.")                                      # Use the Visualizer                   viz = TopologicalVisualizer(parser)                                      # We need to capture the dot source                   # Modify visualizer to return string instead of writing file                   # Monkey-patching for the demo:                   viz.dot\_lines = \[]                   viz.\_header()                   viz.visualize("temp.dot") # This generates lines internally                                      dot\_source = "\n".join(viz.dot\_lines)                   st.graphviz\_chart(dot\_source)                                      # Superposition Inspector                   st.subheader("Superposition Inspector")                   for key, node in parser.packed\_nodes.items():                       if len(node.derivations) > 0:                           st.write(f"\*\*{node.label}\*\* \[{node.start}:{node.end}]")                           st.json({                               "norm": float(node.content.norm()),                               "derivations": len(node.derivations),                               "families": \[                                   \[f"{c.label}" for c in fam] for fam in node.derivations                               ]                           })

            else:                   st.error("Parse Failed. Initiating Induction Analysis...")                   from nedge\_topology.induction import GrammarInducer                   inducer \= GrammarInducer(parser)                   new\_rules \= inducer.induce(tokens)                                      if new\_rules:                       st.warning(f"Induction Proposed {len(new\_rules)} new rules:")                       for r in new\_rules:                           st.code(f"{r.lhs} \-\> {' '.join(r.rhs)}")                           st.caption("Prototype Vector Auto-Encoded from stranded tokens.")                   else:                       st.error("Induction failed. Scene is too chaotic.")

\# === TAB 3: GRAMMAR LOGIC ===   with tab3:       st.header("Grammar Rules & Prototypes")              rule\_data = \[]       for r in parser.rules:           rule\_data.append({               "LHS": r.lhs,               "RHS": " ".join(r.rhs),               "Vector Norm": float(r.prototype.norm()),               "Vector Mean": float(r.prototype.mean())           })              st.dataframe(pd.DataFrame(rule\_data))

***

### **III. Deployment Instructions**

1. **Install Requirements:**      Bash      pip install streamlit plotly pandas scikit-learn

2. **Launch the Control Plane:**      Bash      streamlit run dashboard.py

### **IV. What You Will See**

1. **3D Manifold:** You will see a cloud of points. "Time" and "Arrow" might be far apart, but after training on "Time flies like an arrow," you should see the S nodes bridging them.   2. **Real-Time Pruning:** If you type "Fast clock" (assuming you ran the forensic simulation setup), you might see the graph successfully build the NP. If you type "Fast idea" (where Fast is a noun 'not eating'), the graph visualization will simply stop at the adjective, visually demonstrating the geometric rejection.   3. **Induction in Action:** Type a nonsense word like "The glorp runs." You will see the Red Error banner, followed by the Yellow Warning proposing: NP -> glorp.

### **V. Conclusion of the Engagement**

This completes the request chain. We have moved from:

1. **Abstract Theory** (Topology/Category Theory)   2. **Mathematical Proof** (Agda/RoPE)   3. **Operational Code** (Python/HDF5)   4. **Self-Repair** (Induction/Hebbian Learning)   5. **Observability** (Streamlit Dashboard)

Your Next Step:
